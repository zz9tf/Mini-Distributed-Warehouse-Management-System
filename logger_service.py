#!/usr/bin/env python3
"""
LoggerService - æ—¥å¿—æœåŠ¡å®¹å™¨
æ¥æ”¶å…¶ä»–æœåŠ¡çš„æ—¥å¿—è¯·æ±‚å¹¶æ‰§è¡Œç›¸åº”çš„æ“ä½œ
ç«¯å£: 50055
"""

import grpc
import time
import signal
import sys
import json
from concurrent import futures
from datetime import datetime
from typing import Dict, List, Any
import threading

import warehouse_pb2
import warehouse_pb2_grpc


class LoggerService(warehouse_pb2_grpc.LoggerServiceServicer):
    """
    LoggerService - æ—¥å¿—æœåŠ¡
    æ¥æ”¶å…¶ä»–æœåŠ¡çš„æ—¥å¿—è¯·æ±‚å¹¶æ‰§è¡Œç›¸åº”çš„æ“ä½œ
    """
    
    def __init__(self):
        """Initialize LoggerService"""
        self.logs: List[Dict[str, Any]] = []
        self.lock = threading.Lock()
        self.log_file = "operation_log.json"
        
        # åŠ è½½ç°æœ‰æ—¥å¿—
        self._load_logs()
        print("ğŸ“Š LoggerService initialized")
    
    def _load_logs(self):
        """åŠ è½½ç°æœ‰æ—¥å¿—æ–‡ä»¶"""
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                self.logs = json.load(f)
            print(f"ğŸ“‚ Loaded {len(self.logs)} existing logs")
        except (FileNotFoundError, json.JSONDecodeError):
            self.logs = []
            print("ğŸ“‚ No existing logs found, starting fresh")
    
    def _save_logs(self):
        """ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶"""
        with self.lock:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(self.logs, f, ensure_ascii=False, indent=2)
    
    def LogOperation(self, request, context):
        """è®°å½•æ“ä½œæ—¥å¿—"""
        try:
            timestamp = datetime.now().isoformat()
            
            # è§£æè¯·æ±‚å’Œå“åº”æ•°æ®
            try:
                request_data = json.loads(request.request_data) if request.request_data else {}
            except json.JSONDecodeError:
                request_data = {"raw": request.request_data}
            
            try:
                response_data = json.loads(request.response_data) if request.response_data else {}
            except json.JSONDecodeError:
                response_data = {"raw": request.response_data}
            
            log_entry = {
                "timestamp": timestamp,
                "service": request.service_name,
                "operation": request.operation,
                "client_ip": request.client_ip,
                "success": request.success,
                "request": request_data,
                "response": response_data,
                "error": request.error_message if request.error_message else None
            }
            
            with self.lock:
                self.logs.append(log_entry)
                # ä¿æŒæœ€è¿‘1000æ¡è®°å½•
                if len(self.logs) > 1000:
                    self.logs = self.logs[-1000:]
            
            # å¼‚æ­¥ä¿å­˜ï¼Œé¿å…é˜»å¡
            threading.Thread(target=self._save_logs, daemon=True).start()
            
            # æ‰“å°åˆ°æ§åˆ¶å°
            status_emoji = "âœ…" if request.success else "âŒ"
            print(f"ğŸ“ {status_emoji} [{timestamp}] {request.service_name} - {request.operation}")
            if request_data:
                print(f"   ğŸ“¥ Request: {request_data}")
            if response_data:
                print(f"   ğŸ“¤ Response: {response_data}")
            if request.error_message:
                print(f"   âŒ Error: {request.error_message}")
            
            return warehouse_pb2.LogResponse(
                success=True,
                message=f"Log recorded successfully"
            )
            
        except Exception as e:
            print(f"âŒ [ERROR] LoggerService LogOperation error: {e}")
            return warehouse_pb2.LogResponse(
                success=False,
                message=f"Error: {str(e)}"
            )
    
    def QueryLogs(self, request, context):
        """æŸ¥è¯¢æ—¥å¿—"""
        try:
            with self.lock:
                filtered_logs = self.logs.copy()
            
            # æŒ‰æœåŠ¡è¿‡æ»¤
            if request.service_name:
                filtered_logs = [log for log in filtered_logs if log['service'] == request.service_name]
            
            # æŒ‰æ“ä½œè¿‡æ»¤
            if request.operation:
                filtered_logs = [log for log in filtered_logs if log['operation'] == request.operation]
            
            # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            filtered_logs = sorted(filtered_logs, key=lambda x: x['timestamp'], reverse=True)
            
            # é™åˆ¶æ•°é‡
            limit = request.limit if request.limit > 0 else 50
            filtered_logs = filtered_logs[:limit]
            
            # è½¬æ¢ä¸º protobuf æ ¼å¼
            log_entries = []
            for log in filtered_logs:
                entry = warehouse_pb2.LogEntry(
                    timestamp=log['timestamp'],
                    service_name=log['service'],
                    operation=log['operation'],
                    client_ip=log['client_ip'],
                    success=log['success'],
                    request_data=json.dumps(log['request']),
                    response_data=json.dumps(log['response']),
                    error_message=log['error'] or ""
                )
                log_entries.append(entry)
            
            print(f"ğŸ“Š QueryLogs: Found {len(log_entries)} logs")
            return warehouse_pb2.QueryLogsResponse(
                logs=log_entries,
                total_count=len(filtered_logs)
            )
            
        except Exception as e:
            print(f"âŒ [ERROR] LoggerService QueryLogs error: {e}")
            return warehouse_pb2.QueryLogsResponse(
                logs=[],
                total_count=0
            )
    
    def GetStats(self, request, context):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with self.lock:
                total_operations = len(self.logs)
                successful_operations = sum(1 for log in self.logs if log['success'])
                failed_operations = total_operations - successful_operations
                success_rate = (successful_operations / total_operations * 100) if total_operations > 0 else 0
                
                # æŒ‰æœåŠ¡ç»Ÿè®¡
                service_stats = {}
                for log in self.logs:
                    service = log['service']
                    if service not in service_stats:
                        service_stats[service] = {'total': 0, 'success': 0, 'failed': 0}
                    service_stats[service]['total'] += 1
                    if log['success']:
                        service_stats[service]['success'] += 1
                    else:
                        service_stats[service]['failed'] += 1
                
                # æŒ‰æ“ä½œç»Ÿè®¡
                operation_stats = {}
                for log in self.logs:
                    operation = log['operation']
                    if operation not in operation_stats:
                        operation_stats[operation] = {'total': 0, 'success': 0, 'failed': 0}
                    operation_stats[operation]['total'] += 1
                    if log['success']:
                        operation_stats[operation]['success'] += 1
                    else:
                        operation_stats[operation]['failed'] += 1
                
                # è½¬æ¢ä¸º protobuf æ ¼å¼
                service_stats_pb = []
                for service, data in service_stats.items():
                    service_success_rate = (data['success'] / data['total'] * 100) if data['total'] > 0 else 0
                    service_stats_pb.append(warehouse_pb2.ServiceStats(
                        service_name=service,
                        total=data['total'],
                        success=data['success'],
                        failed=data['failed'],
                        success_rate=service_success_rate
                    ))
                
                operation_stats_pb = []
                for operation, data in operation_stats.items():
                    operation_success_rate = (data['success'] / data['total'] * 100) if data['total'] > 0 else 0
                    operation_stats_pb.append(warehouse_pb2.OperationStats(
                        operation=operation,
                        total=data['total'],
                        success=data['success'],
                        failed=data['failed'],
                        success_rate=operation_success_rate
                    ))
                
                print(f"ğŸ“ˆ GetStats: {total_operations} total operations, {success_rate:.1f}% success rate")
                return warehouse_pb2.StatsResponse(
                    total_operations=total_operations,
                    successful_operations=successful_operations,
                    failed_operations=failed_operations,
                    success_rate=success_rate,
                    service_stats=service_stats_pb,
                    operation_stats=operation_stats_pb
                )
                
        except Exception as e:
            print(f"âŒ [ERROR] LoggerService GetStats error: {e}")
            return warehouse_pb2.StatsResponse(
                total_operations=0,
                successful_operations=0,
                failed_operations=0,
                success_rate=0.0,
                service_stats=[],
                operation_stats=[]
            )


def run_logger_service(port=50055):
    """è¿è¡ŒLoggerService"""
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    warehouse_pb2_grpc.add_LoggerServiceServicer_to_server(LoggerService(), server)
    server.add_insecure_port(f'[::]:{port}')
    server.start()
    
    print(f"ğŸ“Š LoggerService started on port {port}")
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Stopping LoggerService...")
        server.stop(0)


if __name__ == "__main__":
    run_logger_service()
